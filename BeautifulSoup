from bs4 import BeautifulSoup
import urllib3
import requests
from time import time
from requests import get
from time import sleep
from random import randint
from IPython.core.display import clear_output
from warnings import warn
http = urllib3.PoolManager()

#url = 'http://www.ritchieng.com/machine-learning/deep-learning/tensorflow/deep-neural-nets/'
#response = http.request('GET', url)
#soup = BeautifulSoup(response.data,'html.parser')

#samples = soup.find_all("a", "item-title")
#samples[0]

pages = [str(i) for i in range(1,255)]

names = []
# Preparing the monitoring of the loop
start_time = time()
requests = 0

# For every page
for page in pages:

    # Make a get request
    response = get('https://clutch.co/uk/web-designers?page=' + page)

    # Pause the loop
    sleep(randint(8,15))

    # Monitor the requests
    requests += 1
    elapsed_time = time() - start_time
    print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))
    clear_output(wait = True)

    # Throw a warning for non-200 status codes
    if response.status_code != 200:
        warn('Request: {}; Status code: {}'.format(requests, response.status_code))

    # Break the loop if the number of requests is greater than expected
    if requests > 72:
        warn('Number of requests was greater than expected.')  
        break 

    # Parse the content of the request with BeautifulSoup
    page_html = BeautifulSoup(response.text, 'html.parser')

    # Select all the containers from a single page
    mv_containers = page_html.find_all('div', class_ = 'row provider-row-header')

    for container in mv_containers:

        if container.find('h3', class_ = 'company-name') is not None:

            # Scrape the name
            name = container.h3.a.text
            names.append(name)
        
            # Further example
            m_score = container.find('p', class_ = 'tagline').text
